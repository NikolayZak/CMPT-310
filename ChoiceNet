import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# will need to load the data in later to test and see
# base system for our neural net, will need to make adjustments
class makeChoiceClassifier(nn.Module):
    def __init__(self, num_classes=4):
        # Where define all parts of model
        super(makeChoiceClassifer,self).__init__()
        self.input = nn.Linear(20*30, 128)
        self.hidden = nn.Linear(128, 64)
        self.output = nn.Linear(64,4)
        
    def forward(self, x):
        # connect parts defined and return output
        x = x.view(-1, 20*30)
        x = F.relu(self.input(x))
        x = F.relu(self.hidden(x))
        x = F.log_softmax(self.output(x),dim=1)
        return x

model = makeChoiceClassfier()

# function for training loss, base to be modified later according to
# the needs of our system

loss_func = nn.NLLLoss()
optimizer = optim.Adam(model.parametners(), lr=0.001)

# number of runs through our training data
epochs = 5
for epoch in range(epochs):
    # insert a for loop that goes through and calc loss pm decisions
        # Stuff below go into said forloop
        optimizer.zero_grad()

        output = model(data)# note data, output, and results are placeholders
        loss = loss_function(output, results)

        loss.backward()
        optimizer.step()
    pass

# evaluation function
# currently it is log function, may adjust accordingly
# will return a number that corresponds to a choice
with torch.no_grad():
    log_probabilities = model(data)

probabilities = torch.exp(log_probabilities)

output = np.argmax(probabilities)
